{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atividade 2 - Visão Computacional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O entregável de toda esta atividade vai ser um código-fonte em C. \n",
    "\n",
    "Encorajamos vocês a fazerem vídeos demonstrando o resultado e a postar (pode ser privadamente) no YouTube."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Você deve ter uma folha com o padrão anexo. \n",
    "*Dica:* Se não tiver, é possível fazer também com um tablet ou *smartphone*.\n",
    " \n",
    "<img src=\"folha_atividade.png\" width=300>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 1 - calibração\n",
    "\n",
    "Ouça a explicação do professor sobre o modelo de câmera *pinhole*  e desenhe a medida $f$ que separa o plano focal da pupila da câmera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detalhe como calculou $f$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "514.839020979021"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ho = 14.3\n",
    "d = 18\n",
    "hi = 409.011\n",
    "f = (hi*d)/ho\n",
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2\n",
    "\n",
    "Modifique um dos exemplos `draw_circles_video.py` ou `videoplay.py` para passar a ler dados da webcam e identificar o círculo magenta e o círculo ciano, usando o `inRange`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import widgets, interact, interactive, FloatSlider, IntSlider\n",
    "import auxiliar as aux\n",
    "\n",
    "colorpickercian = widgets.ColorPicker(concise = False,description = 'Escolha uma cor',value = '#032351',disabled = False)\n",
    "\n",
    "colorpickermagent = widgets.ColorPicker(concise = False,description = 'Escolha uma cor',value = '#71141C',disabled = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bc8888ea5a44091831354938bedd46e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>ColorPicker</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "ColorPicker(value='#032351', description='Escolha uma cor')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "colorpickercian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsv1cian, hsv2cian = aux.ranges(colorpickercian.value)\n",
    "hsv1magent, hsv2magent = aux.ranges(colorpickermagent.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import math\n",
    "\n",
    "# Parameters to use when opening the webcam.\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "distanciapixel = 0\n",
    "lower = 0\n",
    "upper = 1\n",
    "\n",
    "def auto_canny(image, sigma=0.33):\n",
    "    # compute the median of the single channel pixel intensities\n",
    "    v = np.median(image)\n",
    "\n",
    "    # apply automatic Canny edge detection using the computed median\n",
    "    lower = int(max(0, (1.0 - sigma) * v))\n",
    "    upper = int(min(255, (1.0 + sigma) * v))\n",
    "    edged = cv2.Canny(image, lower, upper)\n",
    "\n",
    "    # return the edged image\n",
    "    return edged\n",
    "\n",
    "def dst(distanciapixel):\n",
    "    if distanciapixel != 0:\n",
    "        return (514.839020979021*14.3)/distanciapixel\n",
    "    \n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "    \n",
    "def ang(ca, c0):\n",
    "    if ca != 0 and c0 != 0:\n",
    "\n",
    "        return math.degrees(math.atan2((c0),(ca)))\n",
    "\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # Convert the frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray,(5,5),0)\n",
    "    # Detect the edges present in the image\n",
    "    bordas = auto_canny(blur)\n",
    "    \n",
    "    circles = []\n",
    "\n",
    "    circles = None\n",
    "    circles = cv2.HoughCircles(bordas,cv2.HOUGH_GRADIENT,2,40,param1=50,param2=100,minRadius=5,maxRadius=60)\n",
    "    \n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    \n",
    "    maskcian_i, maskmagent_i = cv2.inRange(cv2.cvtColor(frame, cv2.COLOR_BGR2HSV), hsv1cian, hsv2cian), cv2.inRange(cv2.cvtColor(frame, cv2.COLOR_BGR2HSV), hsv1magent, hsv2magent)\n",
    "    maskcian, maskmagent = cv2.morphologyEx(maskcian_i,cv2.MORPH_CLOSE,np.ones((10, 10))), cv2.morphologyEx(maskmagent_i,cv2.MORPH_CLOSE,np.ones((10, 10)))\n",
    "    \n",
    "    mask2 = cv2.bitwise_or(maskcian, maskmagent)\n",
    "    mask_img_ = cv2.bitwise_and(frame, frame, mask=mask2)\n",
    "    \n",
    "    if circles is not None:\n",
    "\n",
    "        circles = np.uint16(np.around(circles))\n",
    "        \n",
    "        mi, ma = np.amin(circles[0,:], axis=0), np.amax(circles[0,:], axis=0)\n",
    "        \n",
    "        distanciapixel = ((ma[0] - mi[0])**2 + (ma[1] - mi[1])**2)**(0.5)\n",
    "\n",
    "        for i in range(len(circles[0,:])):\n",
    "\n",
    "            try:\n",
    "\n",
    "                cv2.circle(mask_img_,(circles[0,:][i][0],circles[0,:][i][1]),circles[0,:][i][2],(0,0,255),2)\n",
    "                cv2.circle(mask_img_,(circles[0,:][i][0],circles[0,:][i][1]),2,(0,0,255),3)\n",
    "                cv2.line(mask_img_,(circles[0,:][i][0],circles[0,:][i][1]),(circles[0,:][i + 1][0],circles[0,:][i + 1][1]),(255,0,0),3)\n",
    "                \n",
    "\n",
    "                \n",
    "#                 if maskcian[circles[0,:][i][0]][circles[0,:][i][1]] == 255:\n",
    "#                     cv2.circle(maskcian,(circles[0,:][i][0],circles[0,:][i][1]),i[2],(255,0,0),5)\n",
    "\n",
    "#                 if maskmagent[circles[0,:][i][0]][circles[0,:][i][1]] == 255:\n",
    "#                     cv2.circle(bordas_color,(circles[0,:][i][0],circles[0,:][i][1]),i[2],(0,0,255),5)\n",
    "    \n",
    "            except:\n",
    "                  pass\n",
    "    \n",
    "    cv2.putText(mask_img_,\"Dist: \" + str(dst(distanciapixel))[:4] + \"cm\",(0,50), font, 1,(255,255,255),2,cv2.LINE_AA)\n",
    "    cv2.putText(mask_img_,\"Angulo cm horiz: \" + str(ang(ma[0] - mi[0], ma[1] - mi[1]))[:4],(0,100), font, 1,(255,255,255),2,cv2.LINE_AA)\n",
    "    cv2.line(mask_img_,(0,int(480/2)),(640,int(480/2)),(0,255,255),2)\n",
    "    cv2.imshow('Detector de circulos', mask_img_)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assumindo que a folha se mantém sempre paralela ao plano de imagem da câmera, imprima a distância entre a folha e sua câmera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 4\n",
    "\n",
    "Trace uma linha entre os centros do círculo magenta e do círculo ciano.\n",
    "\n",
    "Imprima na tela o ângulo entre esta linha e a horizontal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 5\n",
    "\n",
    "Usando transformada de Hough, desenhe um círculo sobre o círculo ciano e outro sobre o círculo magenta.\n",
    "\n",
    "**Desafio bônus**: ser capaz de eliminar circulos espúrios (aqueles que não são os da folha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import math\n",
    "\n",
    "# Parameters to use when opening the webcam.\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "distanciapixel = 0\n",
    "lower = 0\n",
    "upper = 1\n",
    "\n",
    "def auto_canny(image, sigma=0.33):\n",
    "    # compute the median of the single channel pixel intensities\n",
    "    v = np.median(image)\n",
    "\n",
    "    # apply automatic Canny edge detection using the computed median\n",
    "    lower = int(max(0, (1.0 - sigma) * v))\n",
    "    upper = int(min(255, (1.0 + sigma) * v))\n",
    "    edged = cv2.Canny(image, lower, upper)\n",
    "\n",
    "    # return the edged image\n",
    "    return edged\n",
    "\n",
    "def dst(distanciapixel):\n",
    "    if distanciapixel != 0:\n",
    "        return (514.839020979021*14.3)/distanciapixel\n",
    "    \n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "    \n",
    "def ang(ca, c0):\n",
    "    if ca != 0 and c0 != 0:\n",
    "\n",
    "        return math.degrees(math.atan2((c0),(ca)))\n",
    "\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # Convert the frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray,(5,5),0)\n",
    "    # Detect the edges present in the image\n",
    "    bordas = auto_canny(blur)\n",
    "    \n",
    "    circles = []\n",
    "\n",
    "    circles = None\n",
    "    circles = cv2.HoughCircles(bordas,cv2.HOUGH_GRADIENT,2,40,param1=50,param2=100,minRadius=5,maxRadius=60)\n",
    "    \n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    \n",
    "    maskcian_i, maskmagent_i = cv2.inRange(cv2.cvtColor(frame, cv2.COLOR_BGR2HSV), hsv1cian, hsv2cian), cv2.inRange(cv2.cvtColor(frame, cv2.COLOR_BGR2HSV), hsv1magent, hsv2magent)\n",
    "    maskcian, maskmagent = cv2.morphologyEx(maskcian_i,cv2.MORPH_CLOSE,np.ones((10, 10))), cv2.morphologyEx(maskmagent_i,cv2.MORPH_CLOSE,np.ones((10, 10)))\n",
    "    \n",
    "    mask2 = cv2.bitwise_or(maskcian, maskmagent)\n",
    "    mask_img_ = cv2.bitwise_and(frame, frame, mask=mask2)\n",
    "    \n",
    "    if circles is not None:\n",
    "\n",
    "        circles = np.uint16(np.around(circles))\n",
    "        \n",
    "        mi, ma = np.amin(circles[0,:], axis=0), np.amax(circles[0,:], axis=0)\n",
    "        \n",
    "        distanciapixel = ((ma[0] - mi[0])**2 + (ma[1] - mi[1])**2)**(0.5)\n",
    "\n",
    "        for i in range(len(circles[0,:])):\n",
    "\n",
    "            try:\n",
    "\n",
    "                cv2.circle(mask_img_,(circles[0,:][i][0],circles[0,:][i][1]),circles[0,:][i][2],(0,0,255),2)\n",
    "                cv2.circle(mask_img_,(circles[0,:][i][0],circles[0,:][i][1]),2,(0,0,255),3)\n",
    "                cv2.line(mask_img_,(circles[0,:][i][0],circles[0,:][i][1]),(circles[0,:][i + 1][0],circles[0,:][i + 1][1]),(255,0,0),3)\n",
    "                \n",
    "\n",
    "                \n",
    "#                 if maskcian[circles[0,:][i][0]][circles[0,:][i][1]] == 255:\n",
    "#                     cv2.circle(maskcian,(circles[0,:][i][0],circles[0,:][i][1]),i[2],(255,0,0),5)\n",
    "\n",
    "#                 if maskmagent[circles[0,:][i][0]][circles[0,:][i][1]] == 255:\n",
    "#                     cv2.circle(bordas_color,(circles[0,:][i][0],circles[0,:][i][1]),i[2],(0,0,255),5)\n",
    "    \n",
    "            except:\n",
    "                  pass\n",
    "    \n",
    "    \n",
    "    \n",
    "    ############################################\n",
    "    # Número mínimo de pontos correspondentes\n",
    "    MIN_MATCH_COUNT = 10\n",
    "\n",
    "    img_original = cv2.imread('folha_atividade.png',0)      # Gabarito / Imagem a procurar\n",
    "    img_cena = frame # Imagem do cenario - puxe do video para fazer isto\n",
    "\n",
    "    # Versões RGB das imagens, para plot\n",
    "    original_rgb = cv2.cvtColor(img_original, cv2.COLOR_GRAY2RGB)\n",
    "    cena_rgb = cv2.cvtColor(img_cena, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "    # Imagem de saída\n",
    "    out = cena_rgb.copy()\n",
    "\n",
    "\n",
    "    # Cria o detector SIFT\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "    # Encontra os pontos únicos (keypoints) nas duas imagems\n",
    "    kp1, des1 = sift.detectAndCompute(img_original ,None)\n",
    "    kp2, des2 = sift.detectAndCompute(img_cena,None)\n",
    "\n",
    "    # Configurações do algoritmo FLANN que compara keypoints e ver correspondências - não se preocupe com isso\n",
    "    FLANN_INDEX_KDTREE = 0\n",
    "    index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "    search_params = dict(checks = 50)\n",
    "\n",
    "    # Configura o algoritmo de casamento de features que vê *como* o objeto que deve ser encontrado aparece na imagem\n",
    "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "\n",
    "    # Tenta fazer a melhor comparacao usando o algoritmo\n",
    "    matches = flann.knnMatch(des1,des2,k=2)\n",
    "\n",
    "    # store all the good matches as per Lowe's ratio test.\n",
    "    good = []\n",
    "    for m,n in matches:\n",
    "        if m.distance < 0.7*n.distance:\n",
    "            good.append(m)\n",
    "\n",
    "\n",
    "    if len(good)>MIN_MATCH_COUNT:\n",
    "        # Separa os bons matches na origem e no destino\n",
    "        src_pts = np.float32([kp1[m.queryIdx].pt for m in good]).reshape(-1,1,2)\n",
    "        dst_pts = np.float32([kp2[m.trainIdx].pt for m in good]).reshape(-1,1,2)\n",
    "\n",
    "\n",
    "        # Tenta achar uma trasformacao composta de rotacao, translacao e escala que situe uma imagem na outra\n",
    "        # Esta transformação é chamada de homografia \n",
    "        # Para saber mais veja \n",
    "        # https://docs.opencv.org/3.4/d9/dab/tutorial_homography.html\n",
    "        M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,5.0)\n",
    "        matchesMask = mask.ravel().tolist()\n",
    "\n",
    "\n",
    "\n",
    "        h,w = img_original.shape\n",
    "        # Um retângulo com as dimensões da imagem original\n",
    "        pts = np.float32([ [0,0],[0,h-1],[w-1,h-1],[w-1,0] ]).reshape(-1,1,2)\n",
    "\n",
    "        # Transforma os pontos do retângulo para onde estao na imagem destino usando a homografia encontrada\n",
    "        dst = cv2.perspectiveTransform(pts,M)\n",
    "\n",
    "\n",
    "        # Desenha um contorno em vermelho ao redor de onde o objeto foi encontrado\n",
    "        img2b = cv2.polylines(out,[np.int32(dst)],True,(255,0,0),3, cv2.LINE_AA)\n",
    "\n",
    "    else:\n",
    "        print(\"Not enough matches are found - %d/%d\" % (len(good),MIN_MATCH_COUNT))\n",
    "        matchesMask = None\n",
    "\n",
    "    draw_params = dict(matchColor = (0,255,0), # draw matches in green color\n",
    "                       singlePointColor = None,\n",
    "                       matchesMask = matchesMask, # draw only inliers\n",
    "                       flags = 2)\n",
    "\n",
    "    # Vocês não precisam disto: desenham os pontos\n",
    "    draw_points(matches, img_original, img_cena, kp1, kp2)\n",
    "    \n",
    "    #############\n",
    "    \n",
    "    cv2.putText(mask_img_,\"Dist: \" + str(dst(distanciapixel))[:4] + \"cm\",(0,50), font, 1,(255,255,255),2,cv2.LINE_AA)\n",
    "    cv2.putText(mask_img_,\"Angulo cm horiz: \" + str(ang(ma[0] - mi[0], ma[1] - mi[1]))[:4],(0,100), font, 1,(255,255,255),2,cv2.LINE_AA)\n",
    "    cv2.line(mask_img_,(0,int(480/2)),(640,int(480/2)),(0,255,255),2)\n",
    "    cv2.imshow('Detector de circulos', out)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 6\n",
    "\n",
    "Usando `SIFT`, identifique o escrito *Insper* na folha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
